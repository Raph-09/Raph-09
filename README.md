# ğŸ‘‹ HI, I'M RAPHAEL

A versatile Data Scientist with three yearsâ€™ experience analyzing data for insights, building predictive models, and deploying these models into applications to solve business and research problems. My work spans data analysis, data science, machine learning, modern AI, and MLOps, allowing me to bridge the gap between raw data and intelligent, production-ready systems.


---

# ğŸ› ï¸ TECHNICAL SKILLS BY CATEGORY
## ğŸ“Š Data Analysis Skills
- ğŸ—„ï¸ **MySQL**  
- ğŸ“Š **Power BI**  
- ğŸ“ˆ **Tableau**  
- ğŸ¼ **Pandas**  
- ğŸ“‰ **Matplotlib**  
- ğŸŒŠ **Seaborn**  
- ğŸ“Œ **Plotly**
## ğŸ§  Data Science Skills
- ğŸ¤– **Scikit-Learn**  
- ğŸ““ **Jupyter Notebook**  
- â˜ï¸ **Google Colab**  
- âš¡ **XGBoost**  
- ğŸ§© **Keras / TensorFlow**  
- ğŸ—ï¸ **Machine Learning**  
- ğŸ§  **Deep Learning**  
- âœï¸ **Natural Language Processing (NLP)**  

## âš™ï¸ Machine Learning Engineering / MLOps Skills
- ğŸŒ **Flask**  
- ğŸš€ **Streamlit** (for quick prototyping)  
- ğŸ› ï¸ **Modular / Object-Oriented Programming (OOP)**  
- ğŸ“Š **MLflow** (for experiment tracking & model registry)  
- ğŸ“¦ **DVC** (Data Version Control for dataset & model versioning)  
- ğŸ“ **DagsHub** (platform for hosting code, data, and model versions)  
- ğŸ‘€ **EvidentlyAI** (for model monitoring)  
- ğŸ³ **Docker**  
- â˜ï¸ **Azure Container Registry (ACR)**  
- ğŸ“¦ **Azure Container App (ACA)**  

## âœ¨ Generative AI & RAG
- ğŸ¤– **LLM APIs:** Azure OpenAI, Grok, HuggingFace, Gemini API  
- ğŸ§  **Embeddings:** HuggingFace & Gemini Embeddings  
- ğŸ“š **Vector Databases:** Astral Database & FAISS Vector Store  
- ğŸ” **Online Search Tool:** Tavily Search Tool  
- ğŸ› ï¸ **CrewAI** (for agent development)



----I AM STILL STUDYING THIS






---

# ğŸ’¼ Experience

## Data Scientist  
**BIZSTEK GLOBAL Â· Full-time**  
ğŸ—“ï¸ Oct 2022 - Sep 2025 Â· 3 yrs  
ğŸ“ Lagos State, Nigeria Â· Remote  

### Key Responsibilities & Contributions:
1. ğŸ—„ï¸ **Data Collection & Preparation:** Designed and implemented data ingestion and scraping pipelines to gather high-quality datasets from diverse sources.  
2. ğŸ§¹ **Data Cleaning & Feature Engineering:** Preprocessed data, handled missing values, encoded categorical variables, and engineered domain-specific features to enhance model performance.  
3. ğŸ” **Exploratory Data Analysis (EDA):** Conducted in-depth EDA and visualizations using Python (Pandas, Matplotlib, Seaborn) to uncover hidden patterns and actionable insights.  
4. ğŸ¤– **Model Development & Evaluation:** Experimented with machine learning algorithms (Logistic Regression, Random Forest, XGBoost) to select optimal models using metrics such as accuracy, precision, recall, and F1 score.  
5. ğŸš€ **Model Deployment:** Deployed best-performing models into production with Flask, Docker, and Azure, ensuring scalability and smooth integration with business systems.  
6. ğŸ“Š **Performance Monitoring:** Utilized EvidentlyAI to track data drift and model performance, maintaining reliability over time.  
7. ğŸ¤ **Cross-functional Collaboration:** Partnered with developers and business stakeholders to translate analytical insights into practical solutions aligned with strategic goals.  

---

## Data Science Intern  
**iNeuron.ai Â· Full-time**  
ğŸ—“ï¸ May 2021 - Jan 2022 Â· 9 mos  
ğŸ“ India Â· Remote  

### Key Responsibilities & Contributions:
1. ğŸŒŸ **Recommendation Engine Development:** Contributed to building a hyper-personalized recommendation system to boost customer engagement and sales conversion rates.  
2. ğŸ” **Data Exploration & Preprocessing:** Conducted extensive EDA and preprocessing to ensure high-quality, consistent datasets.  
3. ğŸ§© **Feature Engineering:** Created new customer-related features and selected impactful variables to significantly improve model performance.  
4. ğŸ¤– **Algorithm Evaluation:** Tested collaborative and content-based filtering algorithms using libraries like Surprise and Scikit-Learn.  
5. âš™ï¸ **Simulation Testing:** Implemented simulations to evaluate recommendation strategies under varying user behaviors and dataset dynamics.  
6. ğŸ“ˆ **Best Practices Implementation:** Applied ML best practices to fine-tune models, reduce overfitting, and enhance recommendation accuracy.


---

# ğŸš€ Projects

### 1. **Amazon Product Recommender Chatbot**  
The **Amazon Chatbot** is an AI-powered e-commerce assistant designed to answer product-related queries using a **Retrieval-Augmented Generation (RAG)** approach. It leverages Amazon product reviews and titles to deliver **contextually relevant, concise, and helpful responses**.  

The system integrates:  
- **LangChain** for LLM orchestration  
- **HuggingFace embeddings** for semantic understanding  
- **AstraDB vector store** for efficient retrieval  
- **Groq LLM** for fast inference  
- **Flask** for a responsive web interface  

It is **containerized with Docker** and supports **CI/CD via GitHub Actions and DockerHub**, ensuring smooth deployment and scalability. 

* ğŸ”— Repo: [GitHub Repository](https://github.com/Raph-09/AMAZON-PRODUCT-RECOMMENDER-CHATBOT)  

---

### 2. **RAG with Web Search Functionality**  
The **Web-Search AI Assistant** is an intelligent, real-time question-answering system that delivers **accurate, up-to-date, and contextually relevant responses**. Unlike static models, it combines **live web search** with high-performance AI reasoning.  

Key features include:  
- **LangChain** to orchestrate LLMs and search tools  
- **Groq AI models** for ultra-fast and efficient inference  
- **Tavily Search API** for retrieving real-time web information  
- **Flask** for a simple and interactive web interface  

The system is **production-ready**, containerized with **Docker**, and employs a **CI/CD pipeline** to automatically push updates to DockerHub, making it suitable for research, enterprise applications, and scenarios requiring fresh, internet-retrieved knowledge.  

* ğŸ”— Repo: [GitHub Repository](https://github.com/Raph-09/RAG-with-web_search-functionality)

### 3. **Predictive Maintenance with MLOPS**

The purpose of this application is to build a **predictive maintenance system** capable of forecasting machine failures before they occur. It implements a full **MLOps pipeline** to ensure that data processing, model development, deployment, monitoring, and automation are performed in a scalable, reproducible, and production-ready manner. The system supports continuous integration, versioning, containerization, cloud deployment, and real-time monitoring of model performance.

* ğŸ”— Repo: [[Link to GitHub Repository](https://github.com/Raph-09/Predictive-Maintenance-with-MLOps)]

### 4. **Adversarial Machine Learning for Intrusion Detection**

This experiment was performed to determine the effectiveness of the proposed defence technique against evasion attacks. The IDS model was built using the CICIDS 2017 dataset found on open-source platforms like Kaggle.com. This dataset is chosen because it is used extensively by several researchers for conducting similar research (Usama et al. 2017; Haroon et al. 2022). The dataset was collected using the Python programming language and downloaded into a notebook environment for processing and analysis. After the dataset was prepared, it was used to train a decision tree algorithm to develop an IDS for detecting network intrusion. Three Different attacks were used to test the vulnerability and robustness of the trained decision tree model, of which the performance deteriorated greatly. The proposed defence of adversarial training with an ensemble classifier was put to the test by training the Adaboost, an ensembled technique, on the generated perturbated examples, and the model recorded improved performance on both seen and unseen perturbations.

* ğŸ”— Repo: [[Link to Colab Notebook]([https://github.com/Raph-09/dversarial_Machine_learning_Framework_for_Enhancing_the_Robustness_of_IDS_against_Evasion_Attacks./blob/main/Adversarial_Machine_learning_Framework_for_Enhancing_the_Robustness_of_IDS_against_Evasion_Attacks.ipynb](https://colab.research.google.com/drive/1XKRZLEHR6Mrs0EzDERGVBJdrmnhI3nQg?usp=sharing))]

### 5. **RepurposeAI  App using Gemini api**

Repurpose AI is an application that transforms long-form blog content into platform-ready social media posts using artificial intelligence. It helps users quickly generate tailored content for platforms like LinkedIn, Instagram, and Facebook with minimal manual editing.

The app uses Streamlit for an easy-to-use web interface, while Google Generative AI handles text generation and embeddings to ensure the posts stay relevant to the original content. To support fast and efficient content retrieval, Repurpose AI uses FAISS as its vector database. Overall, it simplifies content repurposing and helps creators maintain a consistent online presence.

* ğŸ”— Repo: [[Link to GitHub Repository](https://github.com/Raph-09/RepurposeAI-RAG-Application)]

  
### 6. **Phishing Websites Monitoring System (with mlops)**

The Phishing Websites Monitoring System is an AI-driven application designed to detect and classify phishing websites by leveraging machine learning techniques. The project implements a full ML lifecycle pipeline, covering data ingestion, preprocessing, transformation, model training, evaluation, deployment, and monitoring.

This system enhances network security by identifying potential phishing threats using a robust model training and tracking infrastructure, supported by MongoDB, Flask, Docker, MLflow, and DagsHub.

Objectives <br/>
Automate the process of ingesting and processing phishing-related data.
Build and validate robust machine learning models for phishing website detection.
Enable real-time monitoring of model performance.
Provide a web-based interface for batch predictions.
Ensure scalability, reproducibility, and traceability using Docker, MLflow, and GitHub.

* ğŸ”— Repo: [[Link to GitHub Repository](https://github.com/Raph-09/Phishing-Webites-Monitoring-System-with-MLOps)]


### 7. **FraudNet-Credit-Card-Threat-Detector**

This project aims to detect fraudulent credit card transactions using machine learning techniques. Credit card fraud continues to be a major global challenge, impacting financial institutions, merchants, and consumers by causing substantial financial losses and security risks. To address this growing problem, the project leverages data-driven approaches to identify unusual or suspicious transaction patterns that may indicate fraudulent activity.

By building and training a machine learning model on historical transaction data, the system can automatically classify incoming transactions as either legitimate or potentially fraudulent. This automated fraud detection approach not only enhances accuracy and response time but also reduces the burden on manual review processes. Ultimately, the project contributes to strengthening financial security, improving trust in digital payment systems, and minimizing the negative impacts of fraudulent activities on businesses and customers.

* ğŸ”— Repo: [[Link to GitHub Repository](https://github.com/Raph-09/FraudNet-Credit-Card-Threat-Detector)]

### 8. **GEMSTONE-IDENTIFICATION-USING-TRANSFER-LEARNING-TECHNIQUES**

This project uses transfer learning techniques to classify seven different types of gemstones. The model is deployed through a Gradio web application, enabling users to upload an image of a gemstone and receive an automated prediction of its type. The system leverages pre-trained convolutional neural networks to extract features and perform accurate classification on the gemstone dataset.

Three models were evaluated for this task. VGG16 achieved a training accuracy of 73% and validation accuracy of 72%, while VGG19 reached 74% training accuracy but slightly lower validation accuracy of 67%. InceptionV3 performed less effectively, with 55% training accuracy and 45% validation accuracy. Overall, the results demonstrate that VGG16 and VGG19 are better suited for gemstone classification, highlighting the value of fine-tuning pre-trained models for domain-specific image recognition tasks.

* ğŸ”— Repo: [[Link to GitHub Repository](https://github.com/Raph-09/GEMSTONE-IDENTIFICATION-USING-TRANSFER-LEARNING-TECHNIQUES)]

### 9. **TrendyAI-LLM-Agents-Application**

TrendyAI is an agentic application that leverages artificial intelligence to identify, fetch, and present trending topics within the technology domain. By integrating the CrewAI library and Google Generative AI, the system can autonomously analyze large volumes of data and generate insightful summaries that highlight the most relevant and current trends in tech. The application features a user-friendly web interface built with Streamlit, allowing users to easily interact with the platform.

With TrendyAI, users can input any technology-related topic, and the application will process the request to deliver a concise, well-structured report on the latest developments and emerging trends associated with that topic. This functionality empowers tech enthusiasts, researchers, and professionals to stay up-to-date with rapidly evolving areas in technology, make informed decisions, and discover new opportunities. By combining advanced AI capabilities with an accessible interface, TrendyAI provides a seamless experience for tracking and understanding tech trends efficiently.

* ğŸ”— Repo: [[Link to GitHub Repository](https://github.com/Raph-09/TrendyAI-LLM-Agents-Application)]
* 

### 10. News-Authenticity-Classification-Using-The-Source



This project aimed to predict the authenticity of news articles using the source of the articles. Basic data cleaning was performed on the dataset and exploratory data analysis techniques were used to explore the data for insights. Various language models, such as unigram, bigram, and trigram, were used to plot word clouds of the most common words in the news articles. A new feature called 'source' was created by combining the 'site_url' and 'text without stopwords' together, and this feature was preprocessed by performing tokenization, stemming, and punctuation removal. The stemmed text was converted into vectors using the TFIDF (Term Frequency Inverse Document Frequency) vectorizer. The vectors were passed into machine learning models: Adaboost, Naive Bayes, and Passive Aggressive Algorithm to make predictions, but there were many false positives and false negatives, indicating an imbalanced dataset. The imbalanced target variable was handled using oversampling, and the performance of the models was improved. Adaboost recorded a baseline accuracy of 85%, Naive Bayes 86%, and Passive Aggressive Algorithm 91%. The performance of the Passive Aggressive classifier and Adaboost model was improved after hyperparameter optimization, but Naive Bayes remained the same. The final model used for predicting the test dataset was the Passive Aggressive Algorithm. Data preprocessing and hyperparameter optimization were crucial in improving the accuracy of these models. Other models such as LSTM and BERT could also be used, but due to time constraints, these models were not used in this study

* ğŸ”— Repo: [[Link to GitHub Repository](https://github.com/Raph-09/News-Authenticity-Classification-Using-The-Source?tab=readme-ov-file)]
  
# ğŸ“š Research Contributions

* **Adversarial ML for Intrusion Detection:** Designed and implemented adversarial training frameworks using boosting ensembles.
* **Explainable AI for Predictive Maintenance:** Integrated SHAP and LIME to build transparent industrial AI systems.
* **LLM-Based Document Processing:** Leveraged Google Gemini for document understanding tasks.

---
